{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7161f50f-14de-4a00-9951-535df873c0d2",
   "metadata": {},
   "source": [
    "# Project 2: Covid ---> III/ Models and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51e2f60-8392-4093-9d1f-a4543cf66f60",
   "metadata": {},
   "source": [
    "The purpose of this file is to test and compare several models on the matrix extracted from the \"II_features-selection\" file (training on data from Europe only). Then we will improve the best model and analyse it. Finally, we will apply this model to other continents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea38c3b3-4b5c-4346-a021-66fd167ed5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score, auc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9743d5-e58e-4dd8-b8b2-7a4eed760c9b",
   "metadata": {},
   "source": [
    "## 1. Literature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae98ebb-8302-4241-b8f5-8c14173f3453",
   "metadata": {},
   "source": [
    "In 2019, the first COVID-19 cases are observed in China. Rapidly, the SARS-Cov2 virus spread worldwide, pushing governments to take strict decisions about the lives of their co-citizens, like containment, to protect the population. Indeed, in some cases, COVID-19 patients ended up in intensive care services and sometimes died.\n",
    "\n",
    "**The aim of our model is, based on easily computable parameters at the study's beginning, to predict whether the patient will be likely to die or if the chance of survival is important.** The point of this study is to help the hospital organise in the case of a high number of cases.\n",
    "\n",
    "\n",
    "The studied dataset stem from the IDDO Data Repository of COVID-19 data. This data was pulled from the underlying data collection projects on 2022-09-01. The data comes from 1,200 institutions from over 45 countries and gather various information from 700,000 hospitalised individuals.\n",
    "\n",
    "To keep only the relevant features, we first dive into the literature, using Meta-analysis papers. First, we have been looking for aggravating factors that will likely lead the patient to ICU.\n",
    "\n",
    "Obesity: according to a meta-analysis by Sales-Peres, there is a correlation between obesity and ICU admission. This paper also concluded that co-morbidities for obese patients, such as hypertension, type 2 diabetes, smoking habit, lung disease, and/or cardiovascular disease lead to a higher chance of ICU admission.\n",
    "Age: patients aged 70 years and above have a higher risk of infection and a higher need for intensive care than patients younger than 70.\n",
    "Sex: men, when infected, have a higher risk of severe COVID-19 disease and a higher need for intensive care than women\\cite{pijls_demographic_2021}.\n",
    "Ethnicity: the risk of contamination was higher in most ethnic minority groups than their White counterparts in North America and Europe. Among people with confirmed infection, African-Americans and Hispanic Americans were also more likely than White Americans to be hospitalised with SARS-CoV-2 infection. However, the probability of ICU admission was equivalent for all groups. Thus, ethnicity is not relevant to our question. \n",
    "Blood tests: Patients with increased pancreatic enzymes, including elevated serum lipase or amylase of either type, had worse clinical outcomes. Lower levels of lymphocytes and hemoglobin; elevated levels of leukocytes, aspartate aminotransferase, alanine aminotransferase, blood creatinine, blood urea nitrogen, high-sensitivity troponin, creatine kinase, high-sensitivity C-reactive protein, interleukin 6, D-dimer, ferritin, lactate dehydrogenase, and procalcitonin; and a high erythrocyte sedimentation rate were also associated with severe COVID-19.  \n",
    "\n",
    "Out of a total of 3009 citations, 17 articles (22 studies, 21 from China and one study from Singapore) with 3396 ranging from 12 to1099 patients were included. Our meta-analyses showed a significant decrease in lymphocyte, monocyte, and eosinophil, hemoglobin, platelet, albumin, serum sodium, lymphocyte to C-reactive protein ratio (LCR), leukocyte to C-reactive protein ratio (LeCR), leukocyte to IL-6 ratio (LeIR), and an increase in the neutrophil, alanine aminotransferase (ALT), aspartate aminotransferase (AST), total bilirubin, blood urea nitrogen (BUN), creatinine (Cr), erythrocyte Sedimentation Rate (ESR), C-reactive protein (CRP), Procalcitonin (PCT), lactate dehydrogenase (LDH), fibrinogen, prothrombin time (PT), D-dimer, glucose level, and neutrophil to lymphocyte ratio (NLR) in the severe group compared with the non-severe group. \n",
    "\n",
    "No significant changes in white blood cells (WBC), Creatine Kinase (CK), troponin I, myoglobin, IL-6 and K between the two groups were observed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250aa15-370f-4871-af7b-abe871e57467",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Load data after data_selection and feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf0746-7fdb-4fcb-8801-af4db0bb2c1b",
   "metadata": {},
   "source": [
    "The file we open already has: \n",
    "- lines with NA for DSDECOD that have been removed\n",
    "- the NAs that have been filled in \n",
    "- the standardisation that has been performed \n",
    "- the features we want to keep that have been selected\n",
    "- the data has been stratified over the continents, and we only kept the data from Europe\n",
    "\n",
    "**WARNING: These are only the data for Europe because we want to do the training only on Europe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b89e6596-eb3c-4383-9d82-b4cf9f55e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file\n",
    "data_folder = op.join(os.getcwd(), \"data\", \"results\")\n",
    "mylist = []\n",
    "for chunk in pd.read_csv(op.join(data_folder, 'df_final_II-FeaturesSelection_train_LogisticRegression_alldata.csv'), sep=',', low_memory=False, chunksize=5000, index_col=0):\n",
    "    mylist.append(chunk)\n",
    "df_train = pd.concat(mylist, axis=0)\n",
    "df_train.name = 'df_train'\n",
    "del mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4797634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = op.join(os.getcwd(), \"data\", \"results\")\n",
    "mylist = []\n",
    "for chunk in pd.read_csv(op.join(data_folder, 'df_final_II-FeaturesSelection_test_LogisticRegression_alldata.csv'), sep=',', low_memory=False, chunksize=5000, index_col=0):\n",
    "    mylist.append(chunk)\n",
    "df_test = pd.concat(mylist, axis=0)\n",
    "df_test.name = 'df_test'\n",
    "del mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed57e35-089f-4979-bbaa-e4e657a24d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IETEST_Acute_Respiratory_Infection</th>\n",
       "      <th>IETEST_Cough</th>\n",
       "      <th>IETEST_Fever</th>\n",
       "      <th>AGE</th>\n",
       "      <th>LBTEST_APTTSTND</th>\n",
       "      <th>LBTEST_AST</th>\n",
       "      <th>LBTEST_CK</th>\n",
       "      <th>LBTEST_FERRITIN</th>\n",
       "      <th>LBTEST_GLUC</th>\n",
       "      <th>LBTEST_HCT</th>\n",
       "      <th>...</th>\n",
       "      <th>LBTEST_K</th>\n",
       "      <th>LBTEST_NEUT</th>\n",
       "      <th>VSTEST_HEIGHT</th>\n",
       "      <th>VSTEST_HR</th>\n",
       "      <th>VSTEST_MAP</th>\n",
       "      <th>VSTEST_OXYSAT</th>\n",
       "      <th>VSTEST_RESP</th>\n",
       "      <th>VSTEST_SYSBP</th>\n",
       "      <th>VSTEST_TEMP</th>\n",
       "      <th>DSDECOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872296</td>\n",
       "      <td>-0.076806</td>\n",
       "      <td>-0.116610</td>\n",
       "      <td>-0.131744</td>\n",
       "      <td>-0.124811</td>\n",
       "      <td>-0.171526</td>\n",
       "      <td>0.130807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017063</td>\n",
       "      <td>-0.143989</td>\n",
       "      <td>-0.123132</td>\n",
       "      <td>-0.325464</td>\n",
       "      <td>-0.108516</td>\n",
       "      <td>0.270696</td>\n",
       "      <td>-0.580347</td>\n",
       "      <td>0.213575</td>\n",
       "      <td>-0.703391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.836853</td>\n",
       "      <td>-0.076806</td>\n",
       "      <td>10.155515</td>\n",
       "      <td>0.849858</td>\n",
       "      <td>-0.124811</td>\n",
       "      <td>-0.281605</td>\n",
       "      <td>0.130807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017063</td>\n",
       "      <td>-0.143989</td>\n",
       "      <td>-0.123132</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>4.164310</td>\n",
       "      <td>0.270696</td>\n",
       "      <td>1.516391</td>\n",
       "      <td>-0.151065</td>\n",
       "      <td>0.686374</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.092832</td>\n",
       "      <td>-0.076806</td>\n",
       "      <td>-0.116610</td>\n",
       "      <td>-0.131744</td>\n",
       "      <td>-0.124811</td>\n",
       "      <td>-0.171526</td>\n",
       "      <td>0.130807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017063</td>\n",
       "      <td>-0.143989</td>\n",
       "      <td>-0.123132</td>\n",
       "      <td>-0.106402</td>\n",
       "      <td>-0.108516</td>\n",
       "      <td>0.166007</td>\n",
       "      <td>-0.449301</td>\n",
       "      <td>-0.078137</td>\n",
       "      <td>-0.107778</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IETEST_Acute_Respiratory_Infection  IETEST_Cough  IETEST_Fever       AGE  \\\n",
       "0                                 0.0           0.0           0.0  0.872296   \n",
       "1                                 0.0           1.0           1.0 -0.836853   \n",
       "2                                 1.0           0.0           0.0  1.092832   \n",
       "\n",
       "   LBTEST_APTTSTND  LBTEST_AST  LBTEST_CK  LBTEST_FERRITIN  LBTEST_GLUC  \\\n",
       "0        -0.076806   -0.116610  -0.131744        -0.124811    -0.171526   \n",
       "1        -0.076806   10.155515   0.849858        -0.124811    -0.281605   \n",
       "2        -0.076806   -0.116610  -0.131744        -0.124811    -0.171526   \n",
       "\n",
       "   LBTEST_HCT  ...  LBTEST_K  LBTEST_NEUT  VSTEST_HEIGHT  VSTEST_HR  \\\n",
       "0    0.130807  ... -0.017063    -0.143989      -0.123132  -0.325464   \n",
       "1    0.130807  ... -0.017063    -0.143989      -0.123132   0.025036   \n",
       "2    0.130807  ... -0.017063    -0.143989      -0.123132  -0.106402   \n",
       "\n",
       "   VSTEST_MAP  VSTEST_OXYSAT  VSTEST_RESP  VSTEST_SYSBP  VSTEST_TEMP  DSDECOD  \n",
       "0   -0.108516       0.270696    -0.580347      0.213575    -0.703391      0.0  \n",
       "1    4.164310       0.270696     1.516391     -0.151065     0.686374      0.0  \n",
       "2   -0.108516       0.166007    -0.449301     -0.078137    -0.107778      1.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d3ad103-ce7d-4ef5-b568-0beaa6cc09f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 21)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc6d4ffb-938f-4d28-a168-92f46635dd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IETEST_Acute_Respiratory_Infection', 'IETEST_Cough', 'IETEST_Fever',\n",
       "       'AGE', 'LBTEST_APTTSTND', 'LBTEST_AST', 'LBTEST_CK', 'LBTEST_FERRITIN',\n",
       "       'LBTEST_GLUC', 'LBTEST_HCT', 'LBTEST_HGB', 'LBTEST_K', 'LBTEST_NEUT',\n",
       "       'VSTEST_HEIGHT', 'VSTEST_HR', 'VSTEST_MAP', 'VSTEST_OXYSAT',\n",
       "       'VSTEST_RESP', 'VSTEST_SYSBP', 'VSTEST_TEMP', 'DSDECOD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b730981c",
   "metadata": {},
   "source": [
    "## 3. Search the best model/algorithm and the best parameters\n",
    "\n",
    "We try to find the best algorithm/model with the best parameters. Then we will improve the best model in a second part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5b93837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into features and label\n",
    "X_train = df_train.loc[:, df_train.columns!='DSDECOD']\n",
    "y_train = df_train['DSDECOD']\n",
    "\n",
    "X_test = df_test.loc[:, df_test.columns!='DSDECOD']\n",
    "y_test = df_test['DSDECOD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c68612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For storage of results for each model\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade6658-bec2-4d54-8557-00d697033f7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1. Model 1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0425d53b-1183-499f-8b8b-4a9a1a866562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic regression:\n",
      "C: 0.1\n",
      "Penalty: l2\n",
      "------------\n",
      "Performance for Logistic regression:\n",
      "  - Accuracy score = 0.68\n",
      "  - F1 score = 0.46\n",
      "  - Precision score = 0.38\n",
      "  - Recall score = 0.57\n",
      "  - ROC AUC score = 0.65\n",
      "  - Average precision score = 0.42\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 90.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Choose parameter values to test for cross-validation\n",
    "param_grid = {\"C\":np.logspace(-3,3,4), \n",
    "              \"penalty\":[\"l2\"]}\n",
    "\n",
    "# Choose the estimator\n",
    "estimator = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'C':best_param['C'], 'penalty':best_param['penalty']}\n",
    "print('Best parameters for Logistic regression:')\n",
    "print('C:', parameters['C'])\n",
    "print('Penalty:', parameters['penalty'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Logistic regression:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Logistic regression\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13710c8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2. Model 2 : K-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a95857cc-79e3-457a-a837-afeb0c07ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for K-Nearest Neighbor:\n",
      "k: 10\n",
      "------------\n",
      "Performance for K-Nearest Neighbor:\n",
      "  - Accuracy score = 0.52\n",
      "  - F1 score = 0.33\n",
      "  - Precision score = 0.24\n",
      "  - Recall score = 0.50\n",
      "  - ROC AUC score = 0.55\n",
      "  - Average precision score = 0.25\n",
      "CPU times: total: 375 ms\n",
      "Wall time: 96.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "<timed exec>:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Choose parameter values to test for cross-validation\n",
    "k_range = list(range(5, 21, 5))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "# Choose the estimator\n",
    "estimator = KNeighborsClassifier()\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'k':best_param['n_neighbors']}\n",
    "print('Best parameters for K-Nearest Neighbor:')\n",
    "print('k:', parameters['k'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for K-Nearest Neighbor:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"K-Nearest Neighbor\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f85e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3. Model 3 : Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b942b1e4-6dfe-4dff-b0fd-53dbf67f3729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM:\n",
      "C: 1\n",
      "gamma: 0.1\n",
      "kernel: rbf\n",
      "------------\n",
      "Performance for SVM:\n",
      "  - Accuracy score = 0.62\n",
      "  - F1 score = 0.15\n",
      "  - Precision score = 0.15\n",
      "  - Recall score = 0.14\n",
      "  - ROC AUC score = 0.59\n",
      "  - Average precision score = 0.27\n",
      "CPU times: total: 297 ms\n",
      "Wall time: 332 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Choose parameter values to test for cross-validation\n",
    "param_grid = {'C': [0.1, 1, 10, 100], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf']} \n",
    "\n",
    "# Choose the estimator\n",
    "estimator = svm.SVC(probability=True)\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'C':best_param['C'], 'gamma':best_param['gamma'], 'kernel':best_param['kernel']}\n",
    "print('Best parameters for SVM:')\n",
    "print('C:', parameters['C'])\n",
    "print('gamma:', parameters['gamma'])\n",
    "print('kernel:', parameters['kernel'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for SVM:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"SVM\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693cf4c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.4. Model 4 : Multi-layer perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cde36199-e2c9-4794-adda-1903f71c33a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MLP:\n",
      "hidden_layer_sizes: 19\n",
      "activation: relu\n",
      "solver: adam\n",
      "alpha: 0.001\n",
      "learning_rate: constant\n",
      "------------\n",
      "Performance for MLP:\n",
      "  - Accuracy score = 0.63\n",
      "  - F1 score = 0.31\n",
      "  - Precision score = 0.28\n",
      "  - Recall score = 0.36\n",
      "  - ROC AUC score = 0.62\n",
      "  - Average precision score = 0.39\n",
      "CPU times: total: 3.12 s\n",
      "Wall time: 3.36 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "<timed exec>:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Choose parameter values to test for cross-validation\n",
    "param_grid = {'hidden_layer_sizes': np.arange(10, 20, 3),\n",
    "              'activation': ['relu'],\n",
    "              'solver': ['sgd', 'adam'],\n",
    "              'alpha': [0.001, 0.05],\n",
    "              'learning_rate': ['constant']}\n",
    "\n",
    "# Choose the estimator\n",
    "estimator = MLPClassifier(max_iter=300)\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'hidden_layer_sizes':best_param['hidden_layer_sizes'], 'activation':best_param['activation'], \n",
    "              'solver':best_param['solver'], 'alpha':best_param['alpha'], 'learning_rate':best_param['learning_rate'], }\n",
    "print('Best parameters for MLP:')\n",
    "print('hidden_layer_sizes:', parameters['hidden_layer_sizes'])\n",
    "print('activation:', parameters['activation'])\n",
    "print('solver:', parameters['solver'])\n",
    "print('alpha:', parameters['alpha'])\n",
    "print('learning_rate:', parameters['learning_rate'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for MLP:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"MLP\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f2453",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.5. Model 5 : Quadratic discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a35f436b-e597-4944-8afb-4b8a1d53fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Quadratic discriminant analysis:\n",
      "reg_param: 0.1\n",
      "------------\n",
      "Performance for Quadratic discriminant analysis:\n",
      "  - Accuracy score = 0.47\n",
      "  - F1 score = 0.36\n",
      "  - Precision score = 0.25\n",
      "  - Recall score = 0.64\n",
      "  - ROC AUC score = 0.53\n",
      "  - Average precision score = 0.32\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 108 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "<timed exec>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Choose parameter values to test for cross-validation\n",
    "param_grid = [{'reg_param': [0.1, 0.2, 0.3, 0.4, 0.5]}]\n",
    "\n",
    "# Choose the estimator\n",
    "estimator = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'reg_param':best_param['reg_param']}\n",
    "print('Best parameters for Quadratic discriminant analysis:')\n",
    "print('reg_param:', parameters['reg_param'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Quadratic discriminant analysis:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Quadratic discriminant analysis\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf8df0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.6. Model 6 : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d61c3bb7-8556-47ce-ac97-7da08520a260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for XGBoost:\n",
      "max_depth: 2\n",
      "n_estimators: 180\n",
      "learning_rate: 0.05\n",
      "------------\n",
      "Performance for XGBoost:\n",
      "  - Accuracy score = 0.73\n",
      "  - F1 score = 0.50\n",
      "  - Precision score = 0.44\n",
      "  - Recall score = 0.57\n",
      "  - ROC AUC score = 0.68\n",
      "  - Average precision score = 0.43\n",
      "CPU times: total: 3min 31s\n",
      "Wall time: 15.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Choose parameter values to test for cross-validation\n",
    "param_grid = {'max_depth': range (2, 10, 1),\n",
    "              'n_estimators': range(60, 220, 40),\n",
    "              'learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "# Choose the estimator\n",
    "estimator = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'max_depth':best_param['max_depth'], 'n_estimators':best_param['n_estimators'], 'learning_rate':best_param['learning_rate']}\n",
    "print('Best parameters for XGBoost:')\n",
    "print('max_depth:', parameters['max_depth'])\n",
    "print('n_estimators:', parameters['n_estimators'])\n",
    "print('learning_rate:', parameters['learning_rate'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for XGBoost:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"XGBoost\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07937a-b0dd-499d-897d-12776796bde1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.7. Models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bfad584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Average precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 180, 'learnin...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quadratic discriminant analysis</th>\n",
       "      <td>{'reg_param': 0.1}</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>{'k': 10}</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>{'hidden_layer_sizes': 19, 'activation': 'relu...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Parameters  \\\n",
       "Model                                                                                \n",
       "XGBoost                          {'max_depth': 2, 'n_estimators': 180, 'learnin...   \n",
       "Logistic regression                                    {'C': 0.1, 'penalty': 'l2'}   \n",
       "Quadratic discriminant analysis                                 {'reg_param': 0.1}   \n",
       "K-Nearest Neighbor                                                       {'k': 10}   \n",
       "MLP                              {'hidden_layer_sizes': 19, 'activation': 'relu...   \n",
       "SVM                                        {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "\n",
       "                                 Accuracy    F1  Precision  Recall  ROC AUC  \\\n",
       "Model                                                                         \n",
       "XGBoost                              0.73  0.50       0.44    0.57     0.68   \n",
       "Logistic regression                  0.68  0.46       0.38    0.57     0.65   \n",
       "Quadratic discriminant analysis      0.47  0.36       0.25    0.64     0.53   \n",
       "K-Nearest Neighbor                   0.52  0.33       0.24    0.50     0.55   \n",
       "MLP                                  0.63  0.31       0.28    0.36     0.62   \n",
       "SVM                                  0.62  0.15       0.15    0.14     0.59   \n",
       "\n",
       "                                 Average precision  \n",
       "Model                                               \n",
       "XGBoost                                       0.43  \n",
       "Logistic regression                           0.42  \n",
       "Quadratic discriminant analysis               0.32  \n",
       "K-Nearest Neighbor                            0.25  \n",
       "MLP                                           0.39  \n",
       "SVM                                           0.27  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = \"F1\", axis=0, ascending=False).round(2).set_index('Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575f2f5-8ec9-4efd-afbf-6f6447fafd1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Improve the best model (XGBoost) and investigate more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7abf83-82fd-43b5-a864-196e47b1ef24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1. Improve XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b6c0526-e7b3-4427-b388-bc0c56a02a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "[12:22:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"gamma\", \"max_depth\" } are not used.\n",
      "\n",
      "Best parameters for XGBoost:\n",
      "n_estimators: 180\n",
      "learning_rate: 0.1\n",
      "reg_alpha: 0.1\n",
      "reg_lambda: 1e-05\n",
      "booster: gblinear\n",
      "------------\n",
      "Performance for XGBoost:\n",
      "  - Accuracy score = 0.67\n",
      "  - F1 score = 0.52\n",
      "  - Precision score = 0.39\n",
      "  - Recall score = 0.79\n",
      "  - ROC AUC score = 0.73\n",
      "  - Average precision score = 0.55\n",
      "CPU times: total: 32.1 s\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Cross-validation with XGBoost\n",
    "# Choose parameter values to test for cross-validation\n",
    "param_grid = {'max_depth': range (2, 10, 1),\n",
    "              'n_estimators': range(60, 220, 40),\n",
    "              'learning_rate': [0.1, 0.01, 0.05, 0.001],\n",
    "              'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100],\n",
    "              'reg_lambda': [1e-5, 1e-2, 0.1, 1, 100],\n",
    "              'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "              'booster': ['gbtree', 'gblinear']}\n",
    "\n",
    "# Choose the estimator\n",
    "estimator = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "# Cross-validation with HalvingRandomSearchCV\n",
    "clf = HalvingRandomSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=2, shuffle=True, random_state=42))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'max_depth':best_param['max_depth'], 'n_estimators':best_param['n_estimators'], 'learning_rate':best_param['learning_rate'],\n",
    "             'reg_alpha':best_param['reg_alpha'], 'reg_lambda':best_param['reg_lambda'], 'gamma':best_param['gamma'], 'booster':best_param['booster']}\n",
    "print('Best parameters for XGBoost:')\n",
    "if (parameters['booster']!='gblinear'):\n",
    "    print('max_depth:', parameters['max_depth'])\n",
    "    print('gamma:', parameters['gamma'])\n",
    "print('n_estimators:', parameters['n_estimators'])\n",
    "print('learning_rate:', parameters['learning_rate'])\n",
    "print('reg_alpha:', parameters['reg_alpha'])\n",
    "print('reg_lambda:', parameters['reg_lambda'])\n",
    "print('booster:', parameters['booster'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for XGBoost:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b37fd99d-2f6a-4960-8547-48ffba150447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IETEST_Acute_Respiratory_Infection</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IETEST_Cough</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IETEST_Fever</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.5080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBTEST_APTTSTND</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBTEST_AST</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBTEST_CK</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBTEST_FERRITIN</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBTEST_GLUC</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBTEST_HCT</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBTEST_HGB</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBTEST_K</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBTEST_NEUT</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSTEST_HEIGHT</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSTEST_HR</th>\n",
       "      <td>0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSTEST_MAP</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSTEST_OXYSAT</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSTEST_RESP</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSTEST_SYSBP</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSTEST_TEMP</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      coef\n",
       "IETEST_Acute_Respiratory_Infection  0.0000\n",
       "IETEST_Cough                        0.0000\n",
       "IETEST_Fever                        0.0000\n",
       "AGE                                 0.5080\n",
       "LBTEST_APTTSTND                     0.0000\n",
       "LBTEST_AST                          0.0000\n",
       "LBTEST_CK                           0.0000\n",
       "LBTEST_FERRITIN                     0.0000\n",
       "LBTEST_GLUC                         0.0000\n",
       "LBTEST_HCT                          0.0000\n",
       "LBTEST_HGB                          0.0000\n",
       "LBTEST_K                            0.0000\n",
       "LBTEST_NEUT                         0.0000\n",
       "VSTEST_HEIGHT                       0.0000\n",
       "VSTEST_HR                           0.0054\n",
       "VSTEST_MAP                          0.0000\n",
       "VSTEST_OXYSAT                       0.0000\n",
       "VSTEST_RESP                         0.0000\n",
       "VSTEST_SYSBP                        0.0000\n",
       "VSTEST_TEMP                         0.0000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See coeffs of the model\n",
    "features = X_train.columns\n",
    "if (parameters['booster']=='gblinear'):\n",
    "    coefs = clf.best_estimator_.coef_\n",
    "    features_XGboost = pd.DataFrame(coefs, index=features, columns=['coef'])\n",
    "else:\n",
    "    feature_importances = clf.best_estimator_.feature_importances_\n",
    "    features_XGboost = pd.DataFrame(feature_importances, index=features, columns=['importance'])\n",
    "\n",
    "features_XGboost.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad52ac9-6f77-4bbd-9a95-766422153d74",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2. Test model for other continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f9df8f7-472d-4e67-abc5-afcdb703763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "df_Asia_self = pd.read_csv(op.join(data_folder, 'df_Asia_SelfStd.csv'), sep=',', index_col=0)\n",
    "df_Asia_NonSelf = pd.read_csv(op.join(data_folder, 'df_Asia_NonSelfStd.csv'), sep=',', index_col=0)\n",
    "\n",
    "df_SouthAmerica_self = pd.read_csv(op.join(data_folder, 'df_SouthAmerica_SelfStd.csv'), sep=',', index_col=0)\n",
    "df_SouthAmerica__NonSelf = pd.read_csv(op.join(data_folder, 'df_SouthAmerica_NonSelfStd.csv'), sep=',', index_col=0)\n",
    "\n",
    "df_NorthAmerica_self = pd.read_csv(op.join(data_folder, 'df_NorthAmerica_SelfStd.csv'), sep=',', index_col=0)\n",
    "df_NorthAmerica_NonSelf = pd.read_csv(op.join(data_folder, 'df_NorthAmerica_NonSelfStd.csv'), sep=',', index_col=0)\n",
    "\n",
    "dfs_continents = [df_Asia_self, df_Asia_NonSelf, df_SouthAmerica_self, df_SouthAmerica__NonSelf, df_NorthAmerica_self, df_NorthAmerica_NonSelf]\n",
    "list_continents = ['Asia_self', 'Asia_NonSelf', 'SouthAmerica_self', 'SouthAmerica__NonSelf', 'NorthAmerica_self', 'NorthAmerica_NonSelf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d185dfc-9149-4313-b63b-09ae4b720fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for other continents with the model XGboost trained on Europe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Average precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asia_self</th>\n",
       "      <td>0.639512</td>\n",
       "      <td>0.269100</td>\n",
       "      <td>0.162799</td>\n",
       "      <td>0.775401</td>\n",
       "      <td>0.763181</td>\n",
       "      <td>0.220854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asia_NonSelf</th>\n",
       "      <td>0.895805</td>\n",
       "      <td>0.217640</td>\n",
       "      <td>0.304487</td>\n",
       "      <td>0.169340</td>\n",
       "      <td>0.762940</td>\n",
       "      <td>0.220508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouthAmerica_self</th>\n",
       "      <td>0.650400</td>\n",
       "      <td>0.345223</td>\n",
       "      <td>0.226589</td>\n",
       "      <td>0.724599</td>\n",
       "      <td>0.737680</td>\n",
       "      <td>0.289089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouthAmerica__NonSelf</th>\n",
       "      <td>0.815848</td>\n",
       "      <td>0.347197</td>\n",
       "      <td>0.316136</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>0.737665</td>\n",
       "      <td>0.289017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NorthAmerica_self</th>\n",
       "      <td>0.636346</td>\n",
       "      <td>0.458180</td>\n",
       "      <td>0.343976</td>\n",
       "      <td>0.685908</td>\n",
       "      <td>0.711008</td>\n",
       "      <td>0.391337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NorthAmerica_NonSelf</th>\n",
       "      <td>0.721218</td>\n",
       "      <td>0.443600</td>\n",
       "      <td>0.401375</td>\n",
       "      <td>0.495756</td>\n",
       "      <td>0.710999</td>\n",
       "      <td>0.391324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Accuracy        F1  Precision    Recall   ROC AUC  \\\n",
       "Asia_self              0.639512  0.269100   0.162799  0.775401  0.763181   \n",
       "Asia_NonSelf           0.895805  0.217640   0.304487  0.169340  0.762940   \n",
       "SouthAmerica_self      0.650400  0.345223   0.226589  0.724599  0.737680   \n",
       "SouthAmerica__NonSelf  0.815848  0.347197   0.316136  0.385027  0.737665   \n",
       "NorthAmerica_self      0.636346  0.458180   0.343976  0.685908  0.711008   \n",
       "NorthAmerica_NonSelf   0.721218  0.443600   0.401375  0.495756  0.710999   \n",
       "\n",
       "                       Average precision  \n",
       "Asia_self                       0.220854  \n",
       "Asia_NonSelf                    0.220508  \n",
       "SouthAmerica_self               0.289089  \n",
       "SouthAmerica__NonSelf           0.289017  \n",
       "NorthAmerica_self               0.391337  \n",
       "NorthAmerica_NonSelf            0.391324  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model on other continents\n",
    "\n",
    "\n",
    "# To store results\n",
    "df_results_others = pd.DataFrame(np.zeros((6, 6)), \n",
    "                                 index = list_continents,\n",
    "                                 columns = ['Accuracy', 'F1', 'Precision', 'Recall', 'ROC AUC', 'Average precision'])\n",
    "\n",
    "\n",
    "# Compute model on other continents\n",
    "\n",
    "for i, dfi in enumerate(dfs_continents):\n",
    "    \n",
    "    name_continent = list_continents[i]\n",
    "    \n",
    "    # Separate in X and y\n",
    "    X_continent = dfi.loc[:, dfi.columns!='DSDECOD']\n",
    "    y_continent = dfi['DSDECOD']\n",
    "    \n",
    "    # Predicting values\n",
    "    y_pred_continent = clf.predict(X_continent)\n",
    "\n",
    "    # Proba for the greater label\n",
    "    y_score_continent = clf.predict_proba(X_continent)[:, 1]\n",
    "    \n",
    "    # Calculate performance scores\n",
    "    df_results_others.loc[name_continent, 'Accuracy'] = accuracy_score(y_continent, y_pred_continent)\n",
    "    df_results_others.loc[name_continent, 'F1'] = f1_score(y_continent, y_pred_continent)\n",
    "    df_results_others.loc[name_continent, 'Precision'] = precision_score(y_continent, y_pred_continent)\n",
    "    df_results_others.loc[name_continent, 'Recall'] = recall_score(y_continent, y_pred_continent)\n",
    "    df_results_others.loc[name_continent, 'ROC AUC'] = roc_auc_score(y_continent, y_score_continent)\n",
    "    df_results_others.loc[name_continent, 'Average precision'] = average_precision_score(y_continent, y_score_continent)\n",
    "\n",
    "    \n",
    "# Display results\n",
    "print('Results for other continents with the model XGboost trained on Europe:')\n",
    "df_results_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "326a5a2b-8faa-4725-bf3e-f77f0b83b1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Europe_test : 46 survivals, 14 deaths, so a 76.67 % survival rate.\n",
      "In Asia : 5994 survivals, 561 deaths, so a 91.44 % survival rate.\n",
      "In SouthAmerica : 5133 survivals, 748 deaths, so a 87.28 % survival rate.\n",
      "In NorthAmerica : 4077 survivals, 1178 deaths, so a 77.58 % survival rate.\n"
     ]
    }
   ],
   "source": [
    "# Reminder: percentage of death\n",
    "dfs = [df_test, df_Asia_self, df_SouthAmerica_self, df_NorthAmerica_self]\n",
    "continents = [\"Europe_test\", \"Asia\", \"SouthAmerica\", \"NorthAmerica\"]\n",
    "for i, dfi in enumerate(dfs):\n",
    "    distribution = dfi['DSDECOD'].value_counts()\n",
    "    print(\"In\", continents[i], \":\", distribution[0], \"survivals,\", distribution[1], \"deaths, so a\", round(distribution[0]/(distribution[0]+distribution[1])*100, 2), \"% survival rate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a5227d-fec6-4585-ba96-a59122c3d9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
