{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7161f50f-14de-4a00-9951-535df873c0d2",
   "metadata": {},
   "source": [
    "# Project 2: Covid ---> III/ Models and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51e2f60-8392-4093-9d1f-a4543cf66f60",
   "metadata": {},
   "source": [
    "The purpose of this file is to test and compare several models on the matrix extracted from the \"II_features-selection\" file. We will use a sample of the data for questions of run time. Then the best model will be applied to all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea38c3b3-4b5c-4346-a021-66fd167ed5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score, auc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9743d5-e58e-4dd8-b8b2-7a4eed760c9b",
   "metadata": {},
   "source": [
    "## 1. Literature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae98ebb-8302-4241-b8f5-8c14173f3453",
   "metadata": {},
   "source": [
    "In 2019, the first COVID-19 cases are observed in China. Rapidly, the SARS-Cov2 virus spread worldwide, pushing governments to take strict decisions about the lives of their co-citizens, like containment, to protect the population. Indeed, in some cases, COVID-19 patients ended up in intensive care services and sometimes died.\n",
    "\n",
    "**The aim of our model is, based on easily computable parameters at the study's beginning, to predict whether the patient will be likely to die or if the chance of survival is important.** The point of this study is to help the hospital organise in the case of a high number of cases.\n",
    "\n",
    "\n",
    "The studied dataset stem from the IDDO Data Repository of COVID-19 data. This data was pulled from the underlying data collection projects on 2022-09-01. The data comes from 1,200 institutions from over 45 countries and gather various information from 700,000 hospitalised individuals.\n",
    "\n",
    "To keep only the relevant features, we first dive into the literature, using Meta-analysis papers. First, we have been looking for aggravating factors that will likely lead the patient to ICU.\n",
    "\n",
    "Obesity: according to a meta-analysis by Sales-Peres, there is a correlation between obesity and ICU admission. This paper also concluded that co-morbidities for obese patients, such as hypertension, type 2 diabetes, smoking habit, lung disease, and/or cardiovascular disease lead to a higher chance of ICU admission.\n",
    "Age: patients aged 70 years and above have a higher risk of infection and a higher need for intensive care than patients younger than 70.\n",
    "Sex: men, when infected, have a higher risk of severe COVID-19 disease and a higher need for intensive care than women\\cite{pijls_demographic_2021}.\n",
    "Ethnicity: the risk of contamination was higher in most ethnic minority groups than their White counterparts in North America and Europe. Among people with confirmed infection, African-Americans and Hispanic Americans were also more likely than White Americans to be hospitalised with SARS-CoV-2 infection. However, the probability of ICU admission was equivalent for all groups. Thus, ethnicity is not relevant to our question. \n",
    "Blood tests: Patients with increased pancreatic enzymes, including elevated serum lipase or amylase of either type, had worse clinical outcomes. Lower levels of lymphocytes and hemoglobin; elevated levels of leukocytes, aspartate aminotransferase, alanine aminotransferase, blood creatinine, blood urea nitrogen, high-sensitivity troponin, creatine kinase, high-sensitivity C-reactive protein, interleukin 6, D-dimer, ferritin, lactate dehydrogenase, and procalcitonin; and a high erythrocyte sedimentation rate were also associated with severe COVID-19.  \n",
    "\n",
    "Out of a total of 3009 citations, 17 articles (22 studies, 21 from China and one study from Singapore) with 3396 ranging from 12 to1099 patients were included. Our meta-analyses showed a significant decrease in lymphocyte, monocyte, and eosinophil, hemoglobin, platelet, albumin, serum sodium, lymphocyte to C-reactive protein ratio (LCR), leukocyte to C-reactive protein ratio (LeCR), leukocyte to IL-6 ratio (LeIR), and an increase in the neutrophil, alanine aminotransferase (ALT), aspartate aminotransferase (AST), total bilirubin, blood urea nitrogen (BUN), creatinine (Cr), erythrocyte Sedimentation Rate (ESR), C-reactive protein (CRP), Procalcitonin (PCT), lactate dehydrogenase (LDH), fibrinogen, prothrombin time (PT), D-dimer, glucose level, and neutrophil to lymphocyte ratio (NLR) in the severe group compared with the non-severe group. \n",
    "\n",
    "No significant changes in white blood cells (WBC), Creatine Kinase (CK), troponin I, myoglobin, IL-6 and K between the two groups were observed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250aa15-370f-4871-af7b-abe871e57467",
   "metadata": {},
   "source": [
    "## 2. Load data after data_selection and feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf0746-7fdb-4fcb-8801-af4db0bb2c1b",
   "metadata": {},
   "source": [
    "The file we open already has: \n",
    "- lines with NA for DSDECOD that have been removed\n",
    "- the NAs that have been filled in \n",
    "- the standardisation that has been performed \n",
    "- the features we want to keep that have been selected\n",
    "- the data has been stratified over the continents, and we only kept the data from Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b89e6596-eb3c-4383-9d82-b4cf9f55e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file\n",
    "data_folder = op.join(os.getcwd(), \"data\", \"results\")\n",
    "mylist = []\n",
    "for chunk in pd.read_csv(op.join(data_folder, 'df_final_II-FeaturesSelection_train_LogisticRegression.csv'), sep=',', low_memory=False, chunksize=5000, index_col=0):\n",
    "    mylist.append(chunk)\n",
    "df_train = pd.concat(mylist, axis=0)\n",
    "df_train.name = 'df_train'\n",
    "del mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4797634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = op.join(os.getcwd(), \"data\", \"results\")\n",
    "mylist = []\n",
    "for chunk in pd.read_csv(op.join(data_folder, 'df_final_II-FeaturesSelection_test_LogisticRegression.csv'), sep=',', low_memory=False, chunksize=5000, index_col=0):\n",
    "    mylist.append(chunk)\n",
    "df_test = pd.concat(mylist, axis=0)\n",
    "df_test.name = 'df_test'\n",
    "del mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fed57e35-089f-4979-bbaa-e4e657a24d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IETEST_Acute_Respiratory_Infection</th>\n",
       "      <th>IETEST_Fever</th>\n",
       "      <th>SACAT_COMORBIDITIES</th>\n",
       "      <th>SACAT_COMPLICATIONS</th>\n",
       "      <th>MBTEST_OTHER RESPIRATORY PATHOGENS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>LBTEST_APTTSTND</th>\n",
       "      <th>LBTEST_CREAT</th>\n",
       "      <th>LBTEST_HGB</th>\n",
       "      <th>LBTEST_NEUT</th>\n",
       "      <th>LBTEST_PT</th>\n",
       "      <th>LBTEST_UREAN</th>\n",
       "      <th>VSTEST_DIABP</th>\n",
       "      <th>VSTEST_HR</th>\n",
       "      <th>VSTEST_SYSBP</th>\n",
       "      <th>DSDECOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.160639</td>\n",
       "      <td>-0.692156</td>\n",
       "      <td>-0.153956</td>\n",
       "      <td>-0.297221</td>\n",
       "      <td>-0.117364</td>\n",
       "      <td>-0.154999</td>\n",
       "      <td>0.176512</td>\n",
       "      <td>-1.410237</td>\n",
       "      <td>-0.245101</td>\n",
       "      <td>2.434560</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.648660</td>\n",
       "      <td>-0.443395</td>\n",
       "      <td>-0.448622</td>\n",
       "      <td>-0.038149</td>\n",
       "      <td>0.094794</td>\n",
       "      <td>-0.154999</td>\n",
       "      <td>-0.483515</td>\n",
       "      <td>1.241241</td>\n",
       "      <td>-0.154442</td>\n",
       "      <td>2.390473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.648660</td>\n",
       "      <td>-0.079822</td>\n",
       "      <td>-0.361561</td>\n",
       "      <td>-0.027354</td>\n",
       "      <td>-0.162770</td>\n",
       "      <td>-0.154999</td>\n",
       "      <td>-0.390880</td>\n",
       "      <td>-0.390437</td>\n",
       "      <td>-0.925036</td>\n",
       "      <td>0.097937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IETEST_Acute_Respiratory_Infection  IETEST_Fever  SACAT_COMORBIDITIES  \\\n",
       "0                                 0.0           0.0                  1.0   \n",
       "1                                 1.0           0.0                  1.0   \n",
       "2                                 0.0           0.0                  1.0   \n",
       "\n",
       "   SACAT_COMPLICATIONS  MBTEST_OTHER RESPIRATORY PATHOGENS       AGE  \\\n",
       "0                  1.0                                 0.0  1.160639   \n",
       "1                  1.0                                 0.0  0.648660   \n",
       "2                  1.0                                 0.0  0.648660   \n",
       "\n",
       "   LBTEST_APTTSTND  LBTEST_CREAT  LBTEST_HGB  LBTEST_NEUT  LBTEST_PT  \\\n",
       "0        -0.692156     -0.153956   -0.297221    -0.117364  -0.154999   \n",
       "1        -0.443395     -0.448622   -0.038149     0.094794  -0.154999   \n",
       "2        -0.079822     -0.361561   -0.027354    -0.162770  -0.154999   \n",
       "\n",
       "   LBTEST_UREAN  VSTEST_DIABP  VSTEST_HR  VSTEST_SYSBP  DSDECOD  \n",
       "0      0.176512     -1.410237  -0.245101      2.434560      0.0  \n",
       "1     -0.483515      1.241241  -0.154442      2.390473      0.0  \n",
       "2     -0.390880     -0.390437  -0.925036      0.097937      0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d3ad103-ce7d-4ef5-b568-0beaa6cc09f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc6d4ffb-938f-4d28-a168-92f46635dd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IETEST_Acute_Respiratory_Infection', 'IETEST_Fever',\n",
       "       'SACAT_COMORBIDITIES', 'SACAT_COMPLICATIONS',\n",
       "       'MBTEST_OTHER RESPIRATORY PATHOGENS', 'AGE', 'LBTEST_APTTSTND',\n",
       "       'LBTEST_CREAT', 'LBTEST_HGB', 'LBTEST_NEUT', 'LBTEST_PT',\n",
       "       'LBTEST_UREAN', 'VSTEST_DIABP', 'VSTEST_HR', 'VSTEST_SYSBP', 'DSDECOD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b730981c",
   "metadata": {},
   "source": [
    "## 3. Search the best model/algorithm and the best parameters\n",
    "\n",
    "We will work only on a sample of the data to try to find the best algorithm/model with the best parameters. Then we will apply the best model to the whole data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5b93837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into features and label\n",
    "X_train = df_train.loc[:, df_train.columns!='DSDECOD']\n",
    "y_train = df_train['DSDECOD']\n",
    "\n",
    "X_test = df_test.loc[:, df_test.columns!='DSDECOD']\n",
    "y_test = df_test['DSDECOD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c68612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For storage of results for each model\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade6658-bec2-4d54-8557-00d697033f7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1. Model 1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0425d53b-1183-499f-8b8b-4a9a1a866562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic regression:\n",
      "C: 10.0\n",
      "Penalty: l2\n",
      "------------\n",
      "Performance for Logistic regression:\n",
      "  - Accuracy score = 0.73\n",
      "  - F1 score = 0.74\n",
      "  - Precision score = 0.70\n",
      "  - Recall score = 0.79\n",
      "  - ROC AUC score = 0.80\n",
      "  - Average precision score = 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\AppData\\Local\\Temp\\ipykernel_5140\\2367574059.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(pd.Series({\"Model\" : \"Logistic regression\",\n"
     ]
    }
   ],
   "source": [
    "# Choose parameter values to test for cross-validation\n",
    "param_grid = {\"C\":np.logspace(-3,3,4), \n",
    "              \"penalty\":[\"l2\"]}\n",
    "\n",
    "# Choose the estimator\n",
    "estimator = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'C':best_param['C'], 'penalty':best_param['penalty']}\n",
    "print('Best parameters for Logistic regression:')\n",
    "print('C:', parameters['C'])\n",
    "print('Penalty:', parameters['penalty'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Logistic regression:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Logistic regression\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13710c8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2. Model 2 : K-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a95857cc-79e3-457a-a837-afeb0c07ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for K-Nearest Neighbor:\n",
      "k: 5\n",
      "------------\n",
      "Performance for K-Nearest Neighbor:\n",
      "  - Accuracy score = 0.68\n",
      "  - F1 score = 0.67\n",
      "  - Precision score = 0.68\n",
      "  - Recall score = 0.66\n",
      "  - ROC AUC score = 0.75\n",
      "  - Average precision score = 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\felic\\AppData\\Local\\Temp\\ipykernel_5140\\896120684.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(pd.Series({\"Model\" : \"K-Nearest Neighbor\",\n"
     ]
    }
   ],
   "source": [
    "# Choose parameter values to test for cross-validation\n",
    "k_range = list(range(5, 21, 5))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "# Choose the estimator\n",
    "estimator = KNeighborsClassifier()\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'k':best_param['n_neighbors']}\n",
    "print('Best parameters for K-Nearest Neighbor:')\n",
    "print('k:', parameters['k'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for K-Nearest Neighbor:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"K-Nearest Neighbor\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f85e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3. Model 3 : Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b942b1e4-6dfe-4dff-b0fd-53dbf67f3729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM:\n",
      "C: 100\n",
      "gamma: 0.001\n",
      "kernel: rbf\n",
      "------------\n",
      "Performance for SVM:\n",
      "  - Accuracy score = 0.72\n",
      "  - F1 score = 0.71\n",
      "  - Precision score = 0.70\n",
      "  - Recall score = 0.72\n",
      "  - ROC AUC score = 0.81\n",
      "  - Average precision score = 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\AppData\\Local\\Temp\\ipykernel_5140\\1202864148.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(pd.Series({\"Model\" : \"SVM\",\n"
     ]
    }
   ],
   "source": [
    "# Choose parameter values to test for cross-validation\n",
    "param_grid = {'C': [0.1, 1, 10, 100], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf']} \n",
    "\n",
    "# Choose the estimator\n",
    "estimator = svm.SVC(probability=True)\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'C':best_param['C'], 'gamma':best_param['gamma'], 'kernel':best_param['kernel']}\n",
    "print('Best parameters for SVM:')\n",
    "print('C:', parameters['C'])\n",
    "print('gamma:', parameters['gamma'])\n",
    "print('kernel:', parameters['kernel'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for SVM:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"SVM\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693cf4c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.4. Model 4 : Multi-layer perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cde36199-e2c9-4794-adda-1903f71c33a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MLP:\n",
      "hidden_layer_sizes: 16\n",
      "activation: relu\n",
      "solver: adam\n",
      "alpha: 0.05\n",
      "learning_rate: constant\n",
      "------------\n",
      "Performance for MLP:\n",
      "  - Accuracy score = 0.70\n",
      "  - F1 score = 0.71\n",
      "  - Precision score = 0.67\n",
      "  - Recall score = 0.76\n",
      "  - ROC AUC score = 0.81\n",
      "  - Average precision score = 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\felic\\AppData\\Local\\Temp\\ipykernel_5140\\885994568.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(pd.Series({\"Model\" : \"MLP\",\n"
     ]
    }
   ],
   "source": [
    "# Choose parameter values to test for cross-validation\n",
    "param_grid = {'hidden_layer_sizes': np.arange(10, 20, 3),\n",
    "              'activation': ['relu'],\n",
    "              'solver': ['sgd', 'adam'],\n",
    "              'alpha': [0.001, 0.05],\n",
    "              'learning_rate': ['constant']}\n",
    "\n",
    "# Choose the estimator\n",
    "estimator = MLPClassifier(max_iter=300)\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'hidden_layer_sizes':best_param['hidden_layer_sizes'], 'activation':best_param['activation'], \n",
    "              'solver':best_param['solver'], 'alpha':best_param['alpha'], 'learning_rate':best_param['learning_rate'], }\n",
    "print('Best parameters for MLP:')\n",
    "print('hidden_layer_sizes:', parameters['hidden_layer_sizes'])\n",
    "print('activation:', parameters['activation'])\n",
    "print('solver:', parameters['solver'])\n",
    "print('alpha:', parameters['alpha'])\n",
    "print('learning_rate:', parameters['learning_rate'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for MLP:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"MLP\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f2453",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.5. Model 5 : Quadratic discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a35f436b-e597-4944-8afb-4b8a1d53fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Quadratic discriminant analysis:\n",
      "reg_param: 0.1\n",
      "------------\n",
      "Performance for Quadratic discriminant analysis:\n",
      "  - Accuracy score = 0.58\n",
      "  - F1 score = 0.63\n",
      "  - Precision score = 0.55\n",
      "  - Recall score = 0.72\n",
      "  - ROC AUC score = 0.73\n",
      "  - Average precision score = 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\felic\\AppData\\Local\\Temp\\ipykernel_5140\\3603112008.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(pd.Series({\"Model\" : \"Quadratic discriminant analysis\",\n"
     ]
    }
   ],
   "source": [
    "# Choose parameter values to test for cross-validation\n",
    "param_grid = [{'reg_param': [0.1, 0.2, 0.3, 0.4, 0.5]}]\n",
    "\n",
    "# Choose the estimator\n",
    "estimator = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'reg_param':best_param['reg_param']}\n",
    "print('Best parameters for Quadratic discriminant analysis:')\n",
    "print('reg_param:', parameters['reg_param'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Quadratic discriminant analysis:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Quadratic discriminant analysis\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf8df0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.6. Model 6 : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d61c3bb7-8556-47ce-ac97-7da08520a260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for XGBoost:\n",
      "max_depth: 4\n",
      "n_estimators: 60\n",
      "learning_rate: 0.05\n",
      "------------\n",
      "Performance for XGBoost:\n",
      "  - Accuracy score = 0.60\n",
      "  - F1 score = 0.61\n",
      "  - Precision score = 0.58\n",
      "  - Recall score = 0.66\n",
      "  - ROC AUC score = 0.69\n",
      "  - Average precision score = 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felic\\AppData\\Local\\Temp\\ipykernel_5140\\3606011841.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(pd.Series({\"Model\" : \"XGBoost\",\n"
     ]
    }
   ],
   "source": [
    "# Choose parameter values to test for cross-validation\n",
    "param_grid = {'max_depth': range (2, 10, 1),\n",
    "              'n_estimators': range(60, 220, 40),\n",
    "              'learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "# Choose the estimator\n",
    "estimator = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "# Cross-validation with GridSearchCV\n",
    "clf = GridSearchCV(estimator, param_grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "\n",
    "# Fit data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Proba for the greater label\n",
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Best parameters\n",
    "best_param = clf.best_estimator_.get_params()\n",
    "parameters = {'max_depth':best_param['max_depth'], 'n_estimators':best_param['n_estimators'], 'learning_rate':best_param['learning_rate']}\n",
    "print('Best parameters for XGBoost:')\n",
    "print('max_depth:', parameters['max_depth'])\n",
    "print('n_estimators:', parameters['n_estimators'])\n",
    "print('learning_rate:', parameters['learning_rate'])\n",
    "print('------------')\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for XGBoost:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "print('  - Average precision score = {:.2f}'.format(average_precision))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"XGBoost\",\n",
    "                                          \"Parameters\": parameters,\n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc,\n",
    "                                          \"Average precision\" : average_precision}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07937a-b0dd-499d-897d-12776796bde1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.7. Models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bfad584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Average precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>{'hidden_layer_sizes': 16, 'activation': 'relu...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>{'k': 5}</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quadratic discriminant analysis</th>\n",
       "      <td>{'reg_param': 0.1}</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 60, 'learning...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Parameters  \\\n",
       "Model                                                                                \n",
       "Logistic regression                                   {'C': 10.0, 'penalty': 'l2'}   \n",
       "SVM                                    {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "MLP                              {'hidden_layer_sizes': 16, 'activation': 'relu...   \n",
       "K-Nearest Neighbor                                                        {'k': 5}   \n",
       "Quadratic discriminant analysis                                 {'reg_param': 0.1}   \n",
       "XGBoost                          {'max_depth': 4, 'n_estimators': 60, 'learning...   \n",
       "\n",
       "                                 Accuracy    F1  Precision  Recall  ROC AUC  \\\n",
       "Model                                                                         \n",
       "Logistic regression                  0.73  0.74       0.70    0.79     0.80   \n",
       "SVM                                  0.72  0.71       0.70    0.72     0.81   \n",
       "MLP                                  0.70  0.71       0.67    0.76     0.81   \n",
       "K-Nearest Neighbor                   0.68  0.67       0.68    0.66     0.75   \n",
       "Quadratic discriminant analysis      0.58  0.63       0.55    0.72     0.73   \n",
       "XGBoost                              0.60  0.61       0.58    0.66     0.69   \n",
       "\n",
       "                                 Average precision  \n",
       "Model                                               \n",
       "Logistic regression                           0.79  \n",
       "SVM                                           0.79  \n",
       "MLP                                           0.81  \n",
       "K-Nearest Neighbor                            0.71  \n",
       "Quadratic discriminant analysis               0.75  \n",
       "XGBoost                                       0.65  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = \"F1\", axis=0, ascending=False).round(2).set_index('Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575f2f5-8ec9-4efd-afbf-6f6447fafd1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Apply the best model/algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38dd3f-277a-496d-a64d-cc8b93d5c89b",
   "metadata": {},
   "source": [
    "**!!TODO!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ba9c2-91d8-4136-babc-28a191fd1306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adeaf62-fafc-4538-8fbf-2736465cc281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080611e-9f3b-4e7a-8959-25c0202c292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAUVEGARDE EN ATTENDANT => obj faire une cross validation quand on a choisi le meilleur modèle !\n",
    "\n",
    "# Perform Logistic regression with cross-validation\n",
    "\n",
    "# Split dataset in features and target variable\n",
    "X_reg = df.loc[:10000, df.columns != 'DSDECOD'].to_numpy()\n",
    "y_reg = df.loc[:10000, df.columns == 'DSDECOD'].to_numpy()\n",
    "\n",
    "# Fill NA values\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "X_reg_woNaN = imputer.fit_transform(X_reg)\n",
    "\n",
    "# Get rid of rows with missing y values\n",
    "X_reg_woNaN = (X_reg_woNaN[~np.isnan(y_reg)[:,0], :])\n",
    "y_reg_woNaN = y_reg[~np.isnan(y_reg)]\n",
    "\n",
    "# Split X and y into training and testing sets\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg_woNaN, y_reg_woNaN, test_size=0.3, random_state=16)\n",
    "\n",
    "# Create pipeline to standardize and make logistic regression\n",
    "pipe_reg = Pipeline([('scl', StandardScaler()), ('clf', LogisticRegression())])\n",
    "\n",
    "# Set parameters to test\n",
    "param_reg = {'clf__penalty': [None, 'l1', 'l2', 'elasticnet']}\n",
    "\n",
    "# Cross-validation\n",
    "cv_reg = RandomizedSearchCV(estimator = pipe_reg, \n",
    "                                         param_distributions=param_reg, \n",
    "                                         cv=3, n_iter=30, n_jobs=-1)\n",
    "\n",
    "# Fit data into the model\n",
    "cv_reg.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "# Predicting values\n",
    "y_reg_pred = cv_reg.predict(X_reg_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "acc_score = accuracy_score(y_reg_pred, y_reg_test)\n",
    "print('Accuracy score for logistic regression : ',acc_score)\n",
    "\n",
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8775a6-dd1c-488d-9758-f80e44d80852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See best parameters of the model\n",
    "g_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d185dfc-9149-4313-b63b-09ae4b720fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See coeffs of the model\n",
    "cv_reg.named_steps['clf'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f945db-4872-49e8-b1f4-7b21e32f9a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee45c12-dfeb-458e-b058-c1a770a14a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
