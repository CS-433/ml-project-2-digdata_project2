{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a17453c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3743b",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4b46ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file\n",
    "data_folder = op.join(os.getcwd(), \"data\", \"results\")\n",
    "mylist = []\n",
    "for chunk in pd.read_csv(op.join(data_folder, 'df_final_I-DataSelection.csv'), sep=',', low_memory=False, chunksize=5000, index_col=0):\n",
    "    mylist.append(chunk)\n",
    "df = pd.concat(mylist, axis=0)\n",
    "df.name = 'df'\n",
    "del mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd092a39",
   "metadata": {},
   "source": [
    "## 2. Stratification per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cca9bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_list = ['CONTINENT_AF', 'CONTINENT_AS', 'CONTINENT_EU','CONTINENT_NA', 'CONTINENT_OC', 'CONTINENT_SA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7a1d9b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2660\\72969642.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_africa.drop(continent_list, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#data afrique\n",
    "df_africa = df[df['CONTINENT_AF'] == 1]\n",
    "df_africa.drop(continent_list, axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9a7e1226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2660\\1254517383.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_asia.drop(continent_list, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#data asia\n",
    "df_asia = df[df['CONTINENT_AS'] == 1]\n",
    "df_asia.drop(continent_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bc2272fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2660\\2754302893.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_europe.drop(continent_list, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#data europe\n",
    "df_europe = df[df['CONTINENT_EU'] == 1]\n",
    "df_europe.drop(continent_list, axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "49c07728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2660\\1140342933.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_south_america.drop(continent_list, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#data south america\n",
    "df_south_america = df[df['CONTINENT_SA'] == 1]\n",
    "df_south_america.drop(continent_list, axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "09d75cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2660\\2672587591.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_north_america.drop(continent_list, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#data north america\n",
    "df_north_america = df[df['CONTINENT_NA'] == 1]\n",
    "df_north_america.drop(continent_list, axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3c24d106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2660\\808876937.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_oceania.drop(continent_list, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#data oceania \n",
    "df_oceania = df[df['CONTINENT_OC'] == 1]\n",
    "df_oceania.drop(continent_list, axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e187c253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size AFRICA: 47985994\n",
      "Data size ASIA: 772534\n",
      "Data size EUROPE: 9024526\n",
      "Data size NORTH AMERICA: 595252\n",
      "Data size SOUTH AMERICA: 605640\n",
      "Data size OCEANIA: 3332\n"
     ]
    }
   ],
   "source": [
    "#relative size of each slice of data\n",
    "print(f\"Data size AFRICA: {df_africa.size}\")\n",
    "print(f\"Data size ASIA: {df_asia.size}\")\n",
    "print(f\"Data size EUROPE: {df_europe.size}\")\n",
    "print(f\"Data size NORTH AMERICA: {df_north_america.size}\")\n",
    "print(f\"Data size SOUTH AMERICA: {df_south_america.size}\")\n",
    "print(f\"Data size OCEANIA: {df_oceania.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c5cf8dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two bigger datasets are AFRICA and EUROPE. We are going to keep working with these lines\n"
     ]
    }
   ],
   "source": [
    "print(\"The two bigger datasets are AFRICA and EUROPE. We are going to keep working with these lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a59e8",
   "metadata": {},
   "source": [
    "## 3. Forcing the dataset to have an equal number of death and survival"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b26917",
   "metadata": {},
   "source": [
    "### 3.1 Check the outcome repartition in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2071ec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA death: 21.60448317481972%\n",
      "AFRICA survival: 78.39551682518028%\n"
     ]
    }
   ],
   "source": [
    "#africa repartition\n",
    "df_africa_death = df_africa[df_africa['DSDECOD']== 1]\n",
    "df_africa_alive = df_africa[df_africa['DSDECOD']== 0]\n",
    "print(f\"AFRICA death: {100*df_africa_death.size/df_africa.size}%\")\n",
    "print(f\"AFRICA survival: {100-100*df_africa_death.size/df_africa.size}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "487e74a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUROPE death: 25.678977488679184%\n",
      "EUROPE survival: 74.32102251132082%\n"
     ]
    }
   ],
   "source": [
    "#europe repartition\n",
    "df_europe_death = df_europe[df_europe['DSDECOD']== 1]\n",
    "df_europe_alive = df_europe[df_europe['DSDECOD']== 0]\n",
    "print(f\"EUROPE death: {100*df_europe_death.size/df_europe.size}%\")\n",
    "print(f\"EUROPE survival: {100-100*df_europe_death.size/df_europe.size}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d263f4f",
   "metadata": {},
   "source": [
    "The data is unbalanced. We would want to force the data repaprtion towards an 50-50% repartition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab3ad7c",
   "metadata": {},
   "source": [
    "### 3.2 Forcing the balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "657f4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "865e3119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2660\\1823467105.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_africa = df_africa_death.append(df_africa_alive, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "#africa\n",
    "df_africa_death = df_africa_death.sample(frac = 1).iloc[0:int(data_set_size/2+1)]\n",
    "df_africa_alive = df_africa_alive.sample(frac = 1).iloc[0:int(data_set_size/2+1)]\n",
    "df_africa = df_africa_death.append(df_africa_alive, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "726e6aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2660\\3983775748.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_europe = df_europe_death.append(df_europe_alive, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "#europe\n",
    "df_europe_death = df_europe_death.sample(frac = 1).iloc[0:int(data_set_size/2)]\n",
    "df_europe_alive = df_europe_alive.sample(frac = 1).iloc[0:int(data_set_size/2)]\n",
    "df_europe = df_europe_death.append(df_europe_alive, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40274311",
   "metadata": {},
   "source": [
    "## 4. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "71fdf12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['DSDECOD',\n",
    "               'SEX',\n",
    "               'HODECOD', \n",
    "               'IETEST_Acute_Respiratory_Infection', 'IETEST_Cough', 'IETEST_Covid_ICU', 'IETEST_Covid_admission', 'IETEST_Dyspnoea_Tachypnoea', 'IETEST_Fever', \n",
    "               'IETEST_Inflammatory_MultiSystem_Syndrome', 'IETEST_noCovid_ICU',               \n",
    "               'INCLAS_VACCINES', \n",
    "               'MBTEST_ADENOVIRUS', 'MBTEST_BACTERIA','MBTEST_INFLUENZA', 'MBTEST_MB_SEVERE_ACUTE_RESP_SYND_CORONAVIRUS', 'MBTEST_OTHER PATHOGENS', \n",
    "               'MBTEST_OTHER RESPIRATORY PATHOGENS', 'MBTEST_RSV', \n",
    "               'RPSTRESC', \n",
    "               'RSCAT_AVPU', \n",
    "               'SACAT_COMORBIDITIES', 'SACAT_COMPLICATIONS', 'SACAT_PREVIOUS_COVID-19_INFECTION', \n",
    "               'SCTEST_Appropriate_Developmental_Age_Indicator', 'SCTEST_Breast_Fed_Indicator', 'SCTEST_Infant_Less_Than_One_Year_Indicator', \n",
    "               'SCTEST_Premature_Birth_Indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6f375679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First for some columns in particular, it is more \"logical\" to put 0 (baseline) to fill NA\n",
    "\n",
    "NA_to_0 = ['HODECOD', \n",
    "           'IETEST_Acute_Respiratory_Infection', 'IETEST_Cough', 'IETEST_Covid_ICU', 'IETEST_Covid_admission', 'IETEST_Dyspnoea_Tachypnoea', 'IETEST_Fever', \n",
    "           'IETEST_Inflammatory_MultiSystem_Syndrome', 'IETEST_noCovid_ICU',  \n",
    "           'INCLAS_VACCINES', \n",
    "           'MBTEST_ADENOVIRUS', 'MBTEST_BACTERIA','MBTEST_INFLUENZA', 'MBTEST_MB_SEVERE_ACUTE_RESP_SYND_CORONAVIRUS', 'MBTEST_OTHER PATHOGENS', \n",
    "           'MBTEST_OTHER RESPIRATORY PATHOGENS', 'MBTEST_RSV', \n",
    "           'RPSTRESC', \n",
    "           'RSCAT_AVPU', \n",
    "           'SACAT_COMORBIDITIES', 'SACAT_COMPLICATIONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9a2291ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA and standardize\n",
    "\n",
    "def preProcess(df_train, df_test, categorical, NA_to_0) :\n",
    "    \n",
    "    # 1. Replace NA by 0 in NA_to_0 columns\n",
    "    \n",
    "    df_train[df_train.columns[df_train.columns.isin(NA_to_0)]] = df_train[df_train.columns[df_train.columns.isin(NA_to_0)]].fillna(0)\n",
    "    df_test[df_test.columns[df_test.columns.isin(NA_to_0)]] = df_test[df_test.columns[df_test.columns.isin(NA_to_0)]].fillna(0)\n",
    "    \n",
    "    # 2. Separate in categorical and continuous columns\n",
    "    \n",
    "    df_train_cat = df_train[df_train.columns[df_train.columns.isin(categorical)]]\n",
    "    df_train_con = df_train[df_train.columns[~df_train.columns.isin(categorical)]]\n",
    "    df_test_cat = df_test[df_test.columns[df_test.columns.isin(categorical)]]\n",
    "    df_test_con = df_test[df_test.columns[~df_test.columns.isin(categorical)]]\n",
    "    \n",
    "    cols_cat = df_train_cat.columns\n",
    "    cols_con = df_train_con.columns\n",
    "    print(cols_con)\n",
    "    \n",
    "    # 3. Fill the missing values \n",
    "        \n",
    "        # For categorical variables\n",
    "    imp_cat = SimpleImputer(strategy = \"most_frequent\")\n",
    "    imp_cat = imp_cat.fit(df_train_cat)\n",
    "    \n",
    "    df_train_cat = imp_cat.transform(df_train_cat)\n",
    "    df_test_cat = imp_cat.transform(df_test_cat)\n",
    "    df_train_cat = pd.DataFrame(df_train_cat, columns=cols_cat)\n",
    "    df_test_cat = pd.DataFrame(df_test_cat, columns=cols_cat)\n",
    "    \n",
    "        # For continuous variables\n",
    "    imp_con = SimpleImputer(strategy = \"median\")\n",
    "    imp_con = imp_con.fit(df_train_con)\n",
    "    print(df_train_con.shape)\n",
    "    df_train_con = imp_con.transform(df_train_con)\n",
    "    print(np.shape(df_train_con))\n",
    "    df_test_con = imp_con.transform(df_test_con)\n",
    "    df_train_con = pd.DataFrame(df_train_con, columns=cols_con)\n",
    "    df_test_con = pd.DataFrame(df_test_con, columns=cols_con)\n",
    "\n",
    "    # 4. Standardization of continuous data\n",
    "    print('hey3')\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(df_train_con)\n",
    "    print('hey4')\n",
    "    df_train_con = scaler.transform(df_train_con)\n",
    "    df_test_con = scaler.transform(df_test_con)\n",
    "    df_train_con = pd.DataFrame(df_train_con, columns=cols_con)\n",
    "    df_test_con = pd.DataFrame(df_test_con, columns=cols_con)\n",
    "    \n",
    "    # 5. Creation of X and y matrixes\n",
    "    print('hey')\n",
    "    df_train = pd.concat([df_train_cat, df_train_con], axis=1)\n",
    "    df_test = pd.concat([df_test_cat, df_test_con], axis=1)\n",
    "    print('nana')\n",
    "    X_train = df_train.loc[:, df_train.columns!='DSDECOD']\n",
    "    y_train = df_train['DSDECOD']\n",
    "    X_test = df_test.loc[:, df_test.columns!='DSDECOD']\n",
    "    y_test = df_test['DSDECOD']\n",
    "    \n",
    "    # 6. Get feature names\n",
    "    print('iccii')\n",
    "    feature_names = df_train.loc[:, df_train.columns!='DSDECOD'].columns\n",
    "    print('laa')\n",
    "    return X_train, y_train, X_test, y_test, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95ae91",
   "metadata": {},
   "source": [
    "### 4.1 Without treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "74681d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_list = ['INCLAS_AGENTS_ACTING_ON_THE_RENIN-ANGIOTENSIN_SYSTEM', 'INCLAS_ANALGESICS', 'INCLAS_ANESTHETICS', \n",
    "               'INCLAS_ANTIBACTERIALS_FOR_SYSTEMIC_USE', 'INCLAS_ANTIHELMINTICS', 'INCLAS_ANTIINFLAMMATORY_AND_ANTIRHEUMATIC_PRODUCTS,_NON-STEROIDS',\n",
    "               'INCLAS_ANTIMALARIALS', 'INCLAS_ANTIMYCOTICS_FOR_SYSTEMIC_USE', 'INCLAS_ANTITHROMBOTIC_AGENTS',\n",
    "               'INCLAS_ANTIVIRALS_FOR_SYSTEMIC_USE', 'INCLAS_ARTIFICIAL_RESPIRATION', 'INCLAS_BETA_BLOCKING_AGENTS',\n",
    "               'INCLAS_BLOOD_SUBSTITUTES_AND_PERFUSION_SOLUTIONS', 'INCLAS_BRONCHOSCOPY', 'INCLAS_CARDIAC_PACING',\n",
    "               'INCLAS_CARDIAC_THERAPY', 'INCLAS_CARDIOPULMONARY_RESUSCITATION', 'INCLAS_CHEMOTHERAPY', 'INCLAS_CORTICOSTEROIDS_FOR_SYSTEMIC_USE',\n",
    "               'INCLAS_DIURETICS', 'INCLAS_DRUGS_FOR_ACID_RELATED_DISORDERS', 'INCLAS_DRUGS_FOR_OBSTRUCTIVE_AIRWAY_DISEASES', 'INCLAS_EXTRACORPOREAL_MEMBRANE_OXYGENATION', \n",
    "               'INCLAS_HIGH_FLOW_OXYGEN_NASAL_CANNULA', 'INCLAS_IMMUNOGLOBULINS', 'INCLAS_IMMUNOSTIMULANTS', 'INCLAS_IMMUNOSUPPRESSANTS', \n",
    "               'INCLAS_INSERTION_OF_TRACHEOSTOMY_TUBE', 'INCLAS_INTUBATION', 'INCLAS_LIPID_MODIFYING_AGENTS', 'INCLAS_MUSCLE_RELAXANTS', \n",
    "               'INCLAS_NONINVASIVE_POSITIVE_PRESSURE_VENTILATION', 'INCLAS_NONINVASIVE_VENTILATION', 'INCLAS_OTHER_RESPIRATORY_SYSTEM_PRODUCTS', \n",
    "               'INCLAS_OXYGEN', 'INCLAS_PERCUTANEOUS_ENDOSCOPIC_GASTROSTOMY', 'INCLAS_PRONE_BODY_POSITION', 'INCLAS_PSYCHOLEPTICS', \n",
    "               'INCLAS_REMOVAL_OF_ENDOTRACHEAL_TUBE', 'INCLAS_RENAL_REPLACEMENT', 'INCLAS_REPLACEMENT_AGENT', 'INCLAS_TOTAL_PARENTERAL_NUTRITION', \n",
    "               'INCLAS_TRANSFUSION_OF_BLOOD_PRODUCT']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5ff60d3",
   "metadata": {},
   "source": [
    "We choose to keep the information about vaccines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c4649",
   "metadata": {},
   "source": [
    "#### 4.1.1 Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e64f00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_africa.drop(treatment_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a193f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_africa_train, df_africa_test = train_test_split(df_africa, test_size=0.3, random_state=16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "95d26290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AGE', 'LBTEST_ALT', 'LBTEST_APTT', 'LBTEST_APTTSTND', 'LBTEST_AST',\n",
      "       'LBTEST_BASEEXCS', 'LBTEST_BICARB', 'LBTEST_BILI', 'LBTEST_CD4',\n",
      "       'LBTEST_CK', 'LBTEST_CREAT', 'LBTEST_CRP', 'LBTEST_FERRITIN',\n",
      "       'LBTEST_GLUC', 'LBTEST_HCT', 'LBTEST_HGB', 'LBTEST_INR', 'LBTEST_K',\n",
      "       'LBTEST_LACTICAC', 'LBTEST_LDH', 'LBTEST_LYM', 'LBTEST_NEUT',\n",
      "       'LBTEST_PCT', 'LBTEST_PH', 'LBTEST_PLAT', 'LBTEST_PT', 'LBTEST_SODIUM',\n",
      "       'LBTEST_UREAN', 'LBTEST_WBC', 'RSCAT_GCS_NINDS_VERSION',\n",
      "       'VSTEST_CPLRFLT', 'VSTEST_DIABP', 'VSTEST_HEIGHT', 'VSTEST_HR',\n",
      "       'VSTEST_MAP', 'VSTEST_OXYSAT', 'VSTEST_RESP', 'VSTEST_SYSBP',\n",
      "       'VSTEST_TEMP', 'VSTEST_WEIGHT'],\n",
      "      dtype='object')\n",
      "(14001, 40)\n",
      "(14001, 31)\n",
      "hey1\n",
      "hey2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (14001, 31), indices imply (14001, 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [162]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_africa_train, y_africa_train, X_africa_test, y_afica_test, features \u001b[38;5;241m=\u001b[39m \u001b[43mpreProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_africa_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_africa_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNA_to_0\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [161]\u001b[0m, in \u001b[0;36mpreProcess\u001b[1;34m(df_train, df_test, categorical, NA_to_0)\u001b[0m\n\u001b[0;32m     39\u001b[0m df_test_con \u001b[38;5;241m=\u001b[39m imp_con\u001b[38;5;241m.\u001b[39mtransform(df_test_con)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhey2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m df_train_con \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_con\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols_con\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhey3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m df_test_con \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df_test_con, columns\u001b[38;5;241m=\u001b[39mcols_con)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    684\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    685\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    686\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    692\u001b[0m         )\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    347\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    348\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    349\u001b[0m )\n\u001b[1;32m--> 351\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    420\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    421\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 422\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (14001, 31), indices imply (14001, 40)"
     ]
    }
   ],
   "source": [
    "X_africa_train, y_africa_train, X_africa_test, y_afica_test, features = preProcess(df_africa_train, df_africa_test, categorical, NA_to_0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9c9d55fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [163]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fit data into the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m clf \u001b[38;5;241m=\u001b[39m LogisticRegression()\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Predicting values\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Logistic regression:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Logistic regression\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
