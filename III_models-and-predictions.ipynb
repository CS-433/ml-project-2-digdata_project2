{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7161f50f-14de-4a00-9951-535df873c0d2",
   "metadata": {},
   "source": [
    "# Project 2: Covid ---> III/ Models and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51e2f60-8392-4093-9d1f-a4543cf66f60",
   "metadata": {},
   "source": [
    "The purpose of this file is to test and compare several models on the matrix extracted from the \"II_features-selection\" file. We will use a sample of the data for questions of run time. Then the best model will be applied to all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea38c3b3-4b5c-4346-a021-66fd167ed5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9743d5-e58e-4dd8-b8b2-7a4eed760c9b",
   "metadata": {},
   "source": [
    "## 1. Literature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae98ebb-8302-4241-b8f5-8c14173f3453",
   "metadata": {},
   "source": [
    "In 2019, the first COVID-19 cases are observed in China. Rapidly, the SARS-Cov2 virus spread worldwide, pushing governments to take strict decisions about the lives of their co-citizens, like containment, to protect the population. Indeed, in some cases, COVID-19 patients ended up in intensive care services and sometimes died.\n",
    "\n",
    "**The aim of our model is, based on easily computable parameters at the study's beginning, to predict whether the patient will be likely to die or if the chance of survival is important.** The point of this study is to help the hospital organise in the case of a high number of cases.\n",
    "\n",
    "\n",
    "The studied dataset stem from the IDDO Data Repository of COVID-19 data. This data was pulled from the underlying data collection projects on 2022-09-01. The data comes from 1,200 institutions from over 45 countries and gather various information from 700,000 hospitalised individuals.\n",
    "\n",
    "To keep only the relevant features, we first dive into the literature, using Meta-analysis papers. First, we have been looking for aggravating factors that will likely lead the patient to ICU.\n",
    "\n",
    "Obesity: according to a meta-analysis by Sales-Peres, there is a correlation between obesity and ICU admission. This paper also concluded that co-morbidities for obese patients, such as hypertension, type 2 diabetes, smoking habit, lung disease, and/or cardiovascular disease lead to a higher chance of ICU admission.\n",
    "Age: patients aged 70 years and above have a higher risk of infection and a higher need for intensive care than patients younger than 70.\n",
    "Sex: men, when infected, have a higher risk of severe COVID-19 disease and a higher need for intensive care than women\\cite{pijls_demographic_2021}.\n",
    "Ethnicity: the risk of contamination was higher in most ethnic minority groups than their White counterparts in North America and Europe. Among people with confirmed infection, African-Americans and Hispanic Americans were also more likely than White Americans to be hospitalised with SARS-CoV-2 infection. However, the probability of ICU admission was equivalent for all groups. Thus, ethnicity is not relevant to our question. \n",
    "Blood tests: Patients with increased pancreatic enzymes, including elevated serum lipase or amylase of either type, had worse clinical outcomes. Lower levels of lymphocytes and hemoglobin; elevated levels of leukocytes, aspartate aminotransferase, alanine aminotransferase, blood creatinine, blood urea nitrogen, high-sensitivity troponin, creatine kinase, high-sensitivity C-reactive protein, interleukin 6, D-dimer, ferritin, lactate dehydrogenase, and procalcitonin; and a high erythrocyte sedimentation rate were also associated with severe COVID-19.  \n",
    "\n",
    "Out of a total of 3009 citations, 17 articles (22 studies, 21 from China and one study from Singapore) with 3396 ranging from 12 to1099 patients were included. Our meta-analyses showed a significant decrease in lymphocyte, monocyte, and eosinophil, hemoglobin, platelet, albumin, serum sodium, lymphocyte to C-reactive protein ratio (LCR), leukocyte to C-reactive protein ratio (LeCR), leukocyte to IL-6 ratio (LeIR), and an increase in the neutrophil, alanine aminotransferase (ALT), aspartate aminotransferase (AST), total bilirubin, blood urea nitrogen (BUN), creatinine (Cr), erythrocyte Sedimentation Rate (ESR), C-reactive protein (CRP), Procalcitonin (PCT), lactate dehydrogenase (LDH), fibrinogen, prothrombin time (PT), D-dimer, glucose level, and neutrophil to lymphocyte ratio (NLR) in the severe group compared with the non-severe group. \n",
    "\n",
    "No significant changes in white blood cells (WBC), Creatine Kinase (CK), troponin I, myoglobin, IL-6 and K between the two groups were observed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250aa15-370f-4871-af7b-abe871e57467",
   "metadata": {},
   "source": [
    "## 2. Load data after data_selection and feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf0746-7fdb-4fcb-8801-af4db0bb2c1b",
   "metadata": {},
   "source": [
    "The file we open already has: \n",
    "- lines with NA for DSDECOD that have been removed\n",
    "- the NAs that have been filled in \n",
    "- the standardisation that has been performed \n",
    "- the features we want to keep that have been selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89e6596-eb3c-4383-9d82-b4cf9f55e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file\n",
    "data_folder = op.join(os.getcwd(), \"data\", \"results\")\n",
    "mylist = []\n",
    "for chunk in pd.read_csv(op.join(data_folder, 'df_final_II-FeaturesSelection_train_svm.csv'), sep=',', low_memory=False, chunksize=5000, index_col=0):\n",
    "    mylist.append(chunk)\n",
    "df_train = pd.concat(mylist, axis=0)\n",
    "df_train.name = 'df_train'\n",
    "del mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4797634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = op.join(os.getcwd(), \"data\", \"results\")\n",
    "mylist = []\n",
    "for chunk in pd.read_csv(op.join(data_folder, 'df_final_II-FeaturesSelection_test_svm.csv'), sep=',', low_memory=False, chunksize=5000, index_col=0):\n",
    "    mylist.append(chunk)\n",
    "df_test = pd.concat(mylist, axis=0)\n",
    "df_test.name = 'df_test'\n",
    "del mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed57e35-089f-4979-bbaa-e4e657a24d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTINENT_AF</th>\n",
       "      <th>CONTINENT_EU</th>\n",
       "      <th>CONTINENT_SA</th>\n",
       "      <th>HODECOD</th>\n",
       "      <th>INCLAS_ANESTHETICS</th>\n",
       "      <th>INCLAS_ANTIHELMINTICS</th>\n",
       "      <th>INCLAS_ANTIINFLAMMATORY_AND_ANTIRHEUMATIC_PRODUCTS,_NON-STEROIDS</th>\n",
       "      <th>INCLAS_ANTIMYCOTICS_FOR_SYSTEMIC_USE</th>\n",
       "      <th>INCLAS_ANTIVIRALS_FOR_SYSTEMIC_USE</th>\n",
       "      <th>INCLAS_ARTIFICIAL_RESPIRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>INCLAS_PSYCHOLEPTICS</th>\n",
       "      <th>INCLAS_REMOVAL_OF_ENDOTRACHEAL_TUBE</th>\n",
       "      <th>INCLAS_RENAL_REPLACEMENT</th>\n",
       "      <th>INCLAS_TOTAL_PARENTERAL_NUTRITION</th>\n",
       "      <th>INCLAS_VACCINES</th>\n",
       "      <th>MBTEST_OTHER RESPIRATORY PATHOGENS</th>\n",
       "      <th>RSCAT_AVPU</th>\n",
       "      <th>LBTEST_AST</th>\n",
       "      <th>LBTEST_LYM</th>\n",
       "      <th>DSDECOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024282</td>\n",
       "      <td>-0.018348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024282</td>\n",
       "      <td>-0.018348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024282</td>\n",
       "      <td>-0.018348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CONTINENT_AF  CONTINENT_EU  CONTINENT_SA  HODECOD  INCLAS_ANESTHETICS  \\\n",
       "0           1.0           0.0           0.0      1.0                 0.0   \n",
       "1           1.0           0.0           0.0      1.0                 0.0   \n",
       "2           1.0           0.0           0.0      1.0                 0.0   \n",
       "\n",
       "   INCLAS_ANTIHELMINTICS  \\\n",
       "0                    0.0   \n",
       "1                    0.0   \n",
       "2                    0.0   \n",
       "\n",
       "   INCLAS_ANTIINFLAMMATORY_AND_ANTIRHEUMATIC_PRODUCTS,_NON-STEROIDS  \\\n",
       "0                                                1.0                  \n",
       "1                                                1.0                  \n",
       "2                                                1.0                  \n",
       "\n",
       "   INCLAS_ANTIMYCOTICS_FOR_SYSTEMIC_USE  INCLAS_ANTIVIRALS_FOR_SYSTEMIC_USE  \\\n",
       "0                                   1.0                                 1.0   \n",
       "1                                   1.0                                 1.0   \n",
       "2                                   1.0                                 1.0   \n",
       "\n",
       "   INCLAS_ARTIFICIAL_RESPIRATION  ...  INCLAS_PSYCHOLEPTICS  \\\n",
       "0                            1.0  ...                   0.0   \n",
       "1                            1.0  ...                   0.0   \n",
       "2                            1.0  ...                   0.0   \n",
       "\n",
       "   INCLAS_REMOVAL_OF_ENDOTRACHEAL_TUBE  INCLAS_RENAL_REPLACEMENT  \\\n",
       "0                                  0.0                       1.0   \n",
       "1                                  0.0                       1.0   \n",
       "2                                  0.0                       1.0   \n",
       "\n",
       "   INCLAS_TOTAL_PARENTERAL_NUTRITION  INCLAS_VACCINES  \\\n",
       "0                                0.0              1.0   \n",
       "1                                0.0              1.0   \n",
       "2                                0.0              1.0   \n",
       "\n",
       "   MBTEST_OTHER RESPIRATORY PATHOGENS  RSCAT_AVPU  LBTEST_AST  LBTEST_LYM  \\\n",
       "0                                 0.0         0.0   -0.024282   -0.018348   \n",
       "1                                 0.0         0.0   -0.024282   -0.018348   \n",
       "2                                 0.0         0.0   -0.024282   -0.018348   \n",
       "\n",
       "   DSDECOD  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6d4ffb-938f-4d28-a168-92f46635dd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CONTINENT_AF', 'CONTINENT_EU', 'CONTINENT_SA', 'HODECOD',\n",
       "       'INCLAS_ANESTHETICS', 'INCLAS_ANTIHELMINTICS',\n",
       "       'INCLAS_ANTIINFLAMMATORY_AND_ANTIRHEUMATIC_PRODUCTS,_NON-STEROIDS',\n",
       "       'INCLAS_ANTIMYCOTICS_FOR_SYSTEMIC_USE',\n",
       "       'INCLAS_ANTIVIRALS_FOR_SYSTEMIC_USE', 'INCLAS_ARTIFICIAL_RESPIRATION',\n",
       "       'INCLAS_BRONCHOSCOPY', 'INCLAS_CARDIAC_THERAPY', 'INCLAS_CHEMOTHERAPY',\n",
       "       'INCLAS_EXTRACORPOREAL_MEMBRANE_OXYGENATION',\n",
       "       'INCLAS_HIGH_FLOW_OXYGEN_NASAL_CANNULA', 'INCLAS_IMMUNOSTIMULANTS',\n",
       "       'INCLAS_INSERTION_OF_TRACHEOSTOMY_TUBE',\n",
       "       'INCLAS_LIPID_MODIFYING_AGENTS', 'INCLAS_MUSCLE_RELAXANTS',\n",
       "       'INCLAS_NONINVASIVE_POSITIVE_PRESSURE_VENTILATION',\n",
       "       'INCLAS_NONINVASIVE_VENTILATION',\n",
       "       'INCLAS_OTHER_RESPIRATORY_SYSTEM_PRODUCTS', 'INCLAS_OXYGEN',\n",
       "       'INCLAS_PERCUTANEOUS_ENDOSCOPIC_GASTROSTOMY',\n",
       "       'INCLAS_PRONE_BODY_POSITION', 'INCLAS_PSYCHOLEPTICS',\n",
       "       'INCLAS_REMOVAL_OF_ENDOTRACHEAL_TUBE', 'INCLAS_RENAL_REPLACEMENT',\n",
       "       'INCLAS_TOTAL_PARENTERAL_NUTRITION', 'INCLAS_VACCINES',\n",
       "       'MBTEST_OTHER RESPIRATORY PATHOGENS', 'RSCAT_AVPU', 'LBTEST_AST',\n",
       "       'LBTEST_LYM', 'DSDECOD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b730981c",
   "metadata": {},
   "source": [
    "## 3. Search the best model/algorithm and the best parameters\n",
    "\n",
    "We will work only on a sample of the data to try to find the best algorithm/model with the best parameters. Then we will apply the best model to the whole data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b93837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into features and label\n",
    "X_train = df_train.loc[:, df_train.columns!='DSDECOD']\n",
    "y_train = df_train['DSDECOD']\n",
    "\n",
    "X_test = df_test.loc[:, df_test.columns!='DSDECOD']\n",
    "y_test = df_test['DSDECOD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c68612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For storage of results for each model\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade6658-bec2-4d54-8557-00d697033f7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1. Model 1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0425d53b-1183-499f-8b8b-4a9a1a866562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Logistic regression:\n",
      "  - Accuracy score = 0.77\n",
      "  - F1 score = 0.12\n",
      "  - Precision score = 0.06\n",
      "  - Recall score = 0.82\n",
      "  - ROC AUC score = 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sande\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Logistic regression:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Logistic regression\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f809a66e-2d05-4fa0-a610-8bb9f430c68f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.2. Model 2: GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc840093-6b49-4fdc-8097-75f75e6b8e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for GradientBoostingClassifier:\n",
      "  - Accuracy score = 0.77\n",
      "  - F1 score = 0.12\n",
      "  - Precision score = 0.07\n",
      "  - Recall score = 0.69\n",
      "  - ROC AUC score = 0.73\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for GradientBoostingClassifier:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"GradientBoostingClassifier\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13710c8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.3. Model 3 : K-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a95857cc-79e3-457a-a837-afeb0c07ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for K-Nearest Neighbor:\n",
      "  - Accuracy score = 0.32\n",
      "  - F1 score = 0.39\n",
      "  - Precision score = 0.89\n",
      "  - Recall score = 0.25\n",
      "  - ROC AUC score = 0.53\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for K-Nearest Neighbor:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"K-Nearest Neighbor\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820d6b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.4. Model 4 : Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9fee1e7-e076-4e22-b79e-5ea350510980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Naive Bayes:\n",
      "  - Accuracy score = 0.75\n",
      "  - F1 score = 0.18\n",
      "  - Precision score = 0.11\n",
      "  - Recall score = 0.45\n",
      "  - ROC AUC score = 0.61\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Naive Bayes:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Naive Bayes\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b1a9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.5. Model 5 : Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c4792a0-9e11-4f15-9386-3485bbb893b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Random Forest:\n",
      "  - Accuracy score = 0.76\n",
      "  - F1 score = 0.13\n",
      "  - Precision score = 0.07\n",
      "  - Recall score = 0.50\n",
      "  - ROC AUC score = 0.63\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Random Forest:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Random Forest\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f85e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.6. Model 6 : Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf9014",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 3.6.1. Normal one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "638ea27f-8453-493f-9bb0-8fad4972d8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Normal SVM:\n",
      "  - Accuracy score = 0.77\n",
      "  - F1 score = 0.11\n",
      "  - Precision score = 0.06\n",
      "  - Recall score = 0.80\n",
      "  - ROC AUC score = 0.78\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = svm.SVC().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Normal SVM:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Normal SVM\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffbc40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 3.6.2. Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b942b1e4-6dfe-4dff-b0fd-53dbf67f3729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Linear SVM:\n",
      "  - Accuracy score = 0.77\n",
      "  - F1 score = 0.11\n",
      "  - Precision score = 0.06\n",
      "  - Recall score = 0.74\n",
      "  - ROC AUC score = 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sande\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = svm.LinearSVC().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Linear SVM:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Linear SVM\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693cf4c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.7. Model 7 : Multi-layer perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cde36199-e2c9-4794-adda-1903f71c33a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for MLP:\n",
      "  - Accuracy score = 0.77\n",
      "  - F1 score = 0.11\n",
      "  - Precision score = 0.06\n",
      "  - Recall score = 0.80\n",
      "  - ROC AUC score = 0.79\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = MLPClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for MLP:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"MLP\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a77bf0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.8. Model 8 : Decision tree classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dec61c30-30e5-4e13-af09-2e0f90f3dee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Decision tree:\n",
      "  - Accuracy score = 0.76\n",
      "  - F1 score = 0.12\n",
      "  - Precision score = 0.07\n",
      "  - Recall score = 0.47\n",
      "  - ROC AUC score = 0.62\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Decision tree:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Decision tree\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4d24a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.9. Model 9 : ADABoost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61714e44-bd17-4387-8cd1-5c2609971bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for AdaBoost:\n",
      "  - Accuracy score = 0.77\n",
      "  - F1 score = 0.12\n",
      "  - Precision score = 0.07\n",
      "  - Recall score = 0.74\n",
      "  - ROC AUC score = 0.76\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = AdaBoostClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for AdaBoost:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"AdaBoost\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a430ba6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.10. Model 10 : Extra trees classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8989eada-81fc-4b25-9b79-155b1bc04826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Extra trees:\n",
      "  - Accuracy score = 0.76\n",
      "  - F1 score = 0.11\n",
      "  - Precision score = 0.06\n",
      "  - Recall score = 0.51\n",
      "  - ROC AUC score = 0.64\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = ExtraTreesClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Extra trees:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Extra trees\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f2453",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.11. Model 11 : Discriminant analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e8204-4576-4590-8c67-9cf70551f35f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 3.11.1. Linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea33cf63-f22f-4715-b874-71a7a3481efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Linear discriminant analysis:\n",
      "  - Accuracy score = 0.77\n",
      "  - F1 score = 0.12\n",
      "  - Precision score = 0.06\n",
      "  - Recall score = 0.73\n",
      "  - ROC AUC score = 0.75\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Linear discriminant analysis:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Linear discriminant analysis\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd4508-b13c-4404-be22-bdb280ebb5f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 3.11.2. Quadratic discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a35f436b-e597-4944-8afb-4b8a1d53fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Quadratic discriminant analysis:\n",
      "  - Accuracy score = 0.26\n",
      "  - F1 score = 0.39\n",
      "  - Precision score = 0.98\n",
      "  - Recall score = 0.24\n",
      "  - ROC AUC score = 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sande\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Quadratic discriminant analysis:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Quadratic discriminant analysis\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e2ed5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.12. Model 12 : Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46a1c8ce-e6c3-4138-97da-ed75c1158977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for SGD:\n",
      "  - Accuracy score = 0.77\n",
      "  - F1 score = 0.12\n",
      "  - Precision score = 0.06\n",
      "  - Recall score = 0.75\n",
      "  - ROC AUC score = 0.76\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = SGDClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for SGD:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"SGD\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf8df0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.13. Model 13 : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d61c3bb7-8556-47ce-ac97-7da08520a260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for XGBoost:\n",
      "  - Accuracy score = 0.76\n",
      "  - F1 score = 0.12\n",
      "  - Precision score = 0.06\n",
      "  - Recall score = 0.59\n",
      "  - ROC AUC score = 0.68\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for XGBoost:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"XGBoost\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e2f54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.14. Model 14 : Gaussian process classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91b1ef22-a1c5-4e50-a472-d566c25fd46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Gaussian process\n",
      "  - Accuracy score = 0.77\n",
      "  - F1 score = 0.12\n",
      "  - Precision score = 0.06\n",
      "  - Recall score = 0.79\n",
      "  - ROC AUC score = 0.78\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = GaussianProcessClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Gaussian process')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Gaussian process\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21869b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.15. Model 15 : Passive aggressive classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ba32ea6-aaee-45d8-9c91-f16df066e83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Passive aggressive:\n",
      "  - Accuracy score = 0.28\n",
      "  - F1 score = 0.39\n",
      "  - Precision score = 0.94\n",
      "  - Recall score = 0.25\n",
      "  - ROC AUC score = 0.52\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = PassiveAggressiveClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Passive aggressive:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Passive aggressive\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f242319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.16. Model 16 : Linear perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13d19149-0dcc-4e8f-a1c6-c14a24326a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Perceptron:\n",
      "  - Accuracy score = 0.77\n",
      "  - F1 score = 0.13\n",
      "  - Precision score = 0.07\n",
      "  - Recall score = 0.70\n",
      "  - ROC AUC score = 0.74\n"
     ]
    }
   ],
   "source": [
    "# Fit data into the model\n",
    "clf = Perceptron().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance scores\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "roc_auc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "# Print performance\n",
    "print('Performance for Perceptron:')\n",
    "print('  - Accuracy score = {:.2f}'.format(accuracy))\n",
    "print('  - F1 score = {:.2f}'.format(f1))\n",
    "print('  - Precision score = {:.2f}'.format(precision))\n",
    "print('  - Recall score = {:.2f}'.format(recall))\n",
    "print('  - ROC AUC score = {:.2f}'.format(roc_auc))\n",
    "\n",
    "# Add performance to df_results\n",
    "df_results = df_results.append(pd.Series({\"Model\" : \"Perceptron\", \n",
    "                                          \"Accuracy\" : accuracy,\n",
    "                                          \"F1\" : f1,\n",
    "                                          \"Precision\": precision,\n",
    "                                          \"Recall\" : recall,\n",
    "                                          \"ROC AUC\" : roc_auc}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07937a-b0dd-499d-897d-12776796bde1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.17. Models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bfad584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Quadratic discriminant analysis</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive aggressive</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear discriminant analysis</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian process</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra trees</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal SVM</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy    F1  Precision  Recall  ROC AUC\n",
       "Model                                                                      \n",
       "Quadratic discriminant analysis      0.26  0.39       0.98    0.24     0.54\n",
       "K-Nearest Neighbor                   0.32  0.39       0.89    0.25     0.53\n",
       "Passive aggressive                   0.28  0.39       0.94    0.25     0.52\n",
       "Naive Bayes                          0.75  0.18       0.11    0.45     0.61\n",
       "Perceptron                           0.77  0.13       0.07    0.70     0.74\n",
       "Random Forest                        0.76  0.13       0.07    0.50     0.63\n",
       "AdaBoost                             0.77  0.12       0.07    0.74     0.76\n",
       "Decision tree                        0.76  0.12       0.07    0.47     0.62\n",
       "GradientBoostingClassifier           0.77  0.12       0.07    0.69     0.73\n",
       "Linear discriminant analysis         0.77  0.12       0.06    0.73     0.75\n",
       "Gaussian process                     0.77  0.12       0.06    0.79     0.78\n",
       "SGD                                  0.77  0.12       0.06    0.75     0.76\n",
       "XGBoost                              0.76  0.12       0.06    0.59     0.68\n",
       "Logistic regression                  0.77  0.12       0.06    0.82     0.79\n",
       "MLP                                  0.77  0.11       0.06    0.80     0.79\n",
       "Extra trees                          0.76  0.11       0.06    0.51     0.64\n",
       "Linear SVM                           0.77  0.11       0.06    0.74     0.75\n",
       "Normal SVM                           0.77  0.11       0.06    0.80     0.78"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = \"F1\", axis=0, ascending=False).round(2).set_index('Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575f2f5-8ec9-4efd-afbf-6f6447fafd1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Apply the best model/algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38dd3f-277a-496d-a64d-cc8b93d5c89b",
   "metadata": {},
   "source": [
    "**!!TODO!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ba9c2-91d8-4136-babc-28a191fd1306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adeaf62-fafc-4538-8fbf-2736465cc281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080611e-9f3b-4e7a-8959-25c0202c292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAUVEGARDE EN ATTENDANT => obj faire une cross validation quand on a choisi le meilleur modèle !\n",
    "\n",
    "# Perform Logistic regression with cross-validation\n",
    "\n",
    "# Split dataset in features and target variable\n",
    "X_reg = df.loc[:10000, df.columns != 'DSDECOD'].to_numpy()\n",
    "y_reg = df.loc[:10000, df.columns == 'DSDECOD'].to_numpy()\n",
    "\n",
    "# Fill NA values\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "X_reg_woNaN = imputer.fit_transform(X_reg)\n",
    "\n",
    "# Get rid of rows with missing y values\n",
    "X_reg_woNaN = (X_reg_woNaN[~np.isnan(y_reg)[:,0], :])\n",
    "y_reg_woNaN = y_reg[~np.isnan(y_reg)]\n",
    "\n",
    "# Split X and y into training and testing sets\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg_woNaN, y_reg_woNaN, test_size=0.3, random_state=16)\n",
    "\n",
    "# Create pipeline to standardize and make logistic regression\n",
    "pipe_reg = Pipeline([('scl', StandardScaler()), ('clf', LogisticRegression())])\n",
    "\n",
    "# Set parameters to test\n",
    "param_reg = {'clf__penalty': [None, 'l1', 'l2', 'elasticnet']}\n",
    "\n",
    "# Cross-validation\n",
    "cv_reg = RandomizedSearchCV(estimator = pipe_reg, \n",
    "                                         param_distributions=param_reg, \n",
    "                                         cv=3, n_iter=30, n_jobs=-1)\n",
    "\n",
    "# Fit data into the model\n",
    "cv_reg.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "# Predicting values\n",
    "y_reg_pred = cv_reg.predict(X_reg_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "acc_score = accuracy_score(y_reg_pred, y_reg_test)\n",
    "print('Accuracy score for logistic regression : ',acc_score)\n",
    "\n",
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8775a6-dd1c-488d-9758-f80e44d80852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See best parameters of the model\n",
    "g_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d185dfc-9149-4313-b63b-09ae4b720fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See coeffs of the model\n",
    "cv_reg.named_steps['clf'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f945db-4872-49e8-b1f4-7b21e32f9a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee45c12-dfeb-458e-b058-c1a770a14a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
